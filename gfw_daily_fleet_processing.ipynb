{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## import libraries\n",
    "from arcgis import GIS\n",
    "import os\n",
    "import pandas as pd\n",
    "import arcpy\n",
    "from arcgis.features import GeoAccessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## define variables\n",
    "# connect to GIS\n",
    "gis = GIS()\n",
    "\n",
    "# directory where the daily fleet csv files from GFW are stored\n",
    "directory = r'F:\\Global Fishing Watch\\Fishing Intensity\\v2\\fleet-daily\\fleet-daily-csvs-100-v2-2020'\n",
    "processing_gdb = r'E:\\analysis\\GFW\\gfw_daily_fleet_2020.gdb'\n",
    "analysis_directory = r'E:\\analysis\\GFW\\TIF\\2020'\n",
    "\n",
    "# To allow overwriting outputs change overwriteOutput option to True.\n",
    "arcpy.env.overwriteOutput = True\n",
    "arcpy.env.parallelProcessingFactor = \"90%\"\n",
    "\n",
    "# Check out any necessary licenses.\n",
    "arcpy.CheckOutExtension(\"spatial\")\n",
    "arcpy.CheckOutExtension(\"ImageAnalyst\")\n",
    "\n",
    "projectCoordinateSystem=\"GEOGCS[\\\"GCS_WGS_1984\\\",DATUM[\\\"D_WGS_1984\\\",SPHEROID[\\\"WGS_1984\\\",6378137.0,298.257223563]],PRIMEM[\\\"Greenwich\\\",0.0],UNIT[\\\"Degree\\\",0.0174532925199433]]\"\n",
    "gear_list = ['fishing', 'drifting_longlines', 'seiners', 'purse_seines', 'tuna_purse_seines', 'other_purse_seines', 'other_seines', 'trollers', 'fixed_gear', 'pots_and_traps', 'set_longlines', 'set_gillnets', 'dredge_fishing', 'squid_jiggers', 'other']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_directories():\n",
    "    # if not arcpy.Exists(processing_gdb):\n",
    "    #     arcpy.management.CreateFileGDB(os.path.dirname(processing_gdb), os.path.basename(processing_gdb))\n",
    "    if not os.path.exists(analysis_directory):\n",
    "        os.makedirs(analysis_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess():\n",
    "            print(\"Starting processing of \" + filename + \"...\")\n",
    "            # Get the full path for the filename\n",
    "            file_path = os.path.join(directory, filename)\n",
    "            # Read the CSV file\n",
    "            print(file_path)\n",
    "            global data\n",
    "            data = pd.read_csv(file_path)\n",
    "            # Get the first row as a table\n",
    "            first_row = data.head(1)\n",
    "            # Get the value in the first column\n",
    "            global value\n",
    "            value = first_row.iloc[0, 0]\n",
    "            # replace the '-' with '_'\n",
    "            value = value.replace('-', '_')\n",
    "            global tif_name1\n",
    "            tif_name1 = os.path.join(analysis_directory, \"daily_fleet_\" + value + \"_hours.tif\")\n",
    "            global fc_hours\n",
    "            fc_hours = os.path.join(processing_gdb, \"daily_fleet_\" + value + \"_hours\")\n",
    "            global tif_name2\n",
    "            tif_name2 = os.path.join(analysis_directory, \"daily_fleet_\" + value + \"_fishhours.tif\")\n",
    "            data['cell_ll_lat'] = data['cell_ll_lat'] + 0.05\n",
    "            data['cell_ll_lon'] = data['cell_ll_lon'] + 0.05\n",
    "            data.rename(columns={'cell_ll_lat': 'lat'}, inplace=True)\n",
    "            data.rename(columns={'cell_ll_lon': 'lon'}, inplace=True)\n",
    "            print(\"Done with \" + value + \"...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_hours():\n",
    "    hours_select = data.loc[data['hours'] != 0]\n",
    "    hours_csv = os.path.join(analysis_directory, \"daily_fleet_\" + value + \"_hours.csv\")\n",
    "    hours_select.drop(columns=['date', 'flag', 'geartype', 'fishing_hours', 'mmsi_present'], inplace=True)\n",
    "    hours_select.to_csv(hours_csv, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_fishhours():\n",
    "    fishhours_select = data.loc[data['fishing_hours'] != 0]\n",
    "    fishhours_csv = os.path.join(analysis_directory, \"daily_fleet_\" + value + \"_fishhours.csv\")\n",
    "    fishhours_select.drop(columns=['date', 'flag', 'geartype', 'hours', 'mmsi_present'], inplace=True)\n",
    "    fishhours_select.to_csv(fishhours_csv, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_directories()\n",
    "\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith('.csv'):\n",
    "        preprocess()\n",
    "        process_hours()\n",
    "        process_fishhours()\n",
    "print(\"All done...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in os.listdir(analysis_directory):\n",
    "    if filename.endswith('fishhours.csv'):\n",
    "        csv_name = (os.path.basename(filename))\n",
    "        print(\"Processing \" + csv_name + \"...\")\n",
    "        fish_csv = (os.path.join(analysis_directory, os.path.splitext(filename)[0] + \".csv\"))\n",
    "        # print(fish_csv)\n",
    "        fish_tif = (os.path.join(analysis_directory, os.path.splitext(filename)[0] + \".tif\"))\n",
    "        # print(fish_tif)\n",
    "        fish_fc = (os.path.join(processing_gdb, os.path.splitext(os.path.basename(filename))[0]))\n",
    "        # print(fish_fc)\n",
    "        arcpy.management.XYTableToPoint(fish_csv, fish_fc, 'lon', 'lat', '', projectCoordinateSystem)\n",
    "        arcpy.conversion.PointToRaster(fish_fc, 'fishing_hours', fish_tif, \"SUM\", 'fishing_hours', 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in os.listdir(analysis_directory):\n",
    "    if filename.endswith('_hours.csv'):\n",
    "        csv_name = (os.path.basename(filename))\n",
    "        print(\"Processing \" + csv_name + \"...\")\n",
    "        hours_csv = (os.path.join(analysis_directory, os.path.splitext(filename)[0] + \".csv\"))\n",
    "        # print(hours_csv)\n",
    "        hours_tif = (os.path.join(analysis_directory, os.path.splitext(filename)[0] + \".tif\"))\n",
    "        # print(hours_tif)\n",
    "        hours_fc = (os.path.join(processing_gdb, os.path.splitext(os.path.basename(filename))[0]))\n",
    "        # print(hours_fc)\n",
    "        arcpy.management.XYTableToPoint(hours_csv, hours_fc, 'lon', 'lat', '', projectCoordinateSystem)\n",
    "        arcpy.conversion.PointToRaster(hours_fc, 'hours', hours_tif, \"SUM\", 'hours', 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a mosaic dataset\n",
    "mosacic_name = 'global_fish_watch_daily_fleet_sum_2000'\n",
    "mosaic_path = os.path.join(processing_gdb, mosacic_name)\n",
    "\n",
    "arcpy.management.CreateMosaicDataset(in_workspace = processing_gdb,\n",
    "                                     in_mosaicdataset_name = mosacic_name,\n",
    "                                     coordinate_system = projectCoordinateSystem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "arcpy.management.AddRastersToMosaicDataset(in_mosaic_dataset = mosaic_path,\n",
    "                                           raster_type = \"Raster Dataset\",\n",
    "                                           input_path = analysis_directory, \n",
    "                                           sub_folder=\"SUBFOLDERS\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arcpy.management.CalculateField(\n",
    "    in_table=mosaic_path,\n",
    "    field=\"date\",\n",
    "    expression=\"\"\"(!Name!.split('_')[3] + \"-\" + !Name!.split('_')[4] + \"-\" + !Name!.split('_')[2])\"\"\",\n",
    "    expression_type=\"PYTHON3\",\n",
    "    code_block=\"\",\n",
    "    field_type=\"DATE\",\n",
    "    enforce_domains=\"NO_ENFORCE_DOMAINS\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arcpy.management.CalculateField(\n",
    "    in_table=mosaic_path,\n",
    "    field=\"variable\",\n",
    "    expression=\"\"\"(!Name!.split('_')[5].split('.')[0])\"\"\",\n",
    "    expression_type=\"PYTHON3\",\n",
    "    code_block=\"\",\n",
    "    field_type=\"TEXT\",\n",
    "    enforce_domains=\"NO_ENFORCE_DOMAINS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mosacic_name = 'global_fish_watch_daily_fleet_sum_2000'\n",
    "mosaic_path = os.path.join(processing_gdb, mosacic_name)\n",
    "\n",
    "arcpy.md.BuildMultidimensionalInfo(in_mosaic_dataset = mosaic_path,\n",
    "                                   variable_field = 'variable',\n",
    "                                   dimension_fields = 'date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages'>Start Time: Wednesday, September 11, 2024 5:03:48 PM<br>Succeeded at Wednesday, September 11, 2024 5:33:49 PM (Elapsed Time: 30 minutes 1 seconds)<br></div><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'E:\\\\analysis\\\\GFW\\\\gfw_daily_fleet_2020.gdb\\\\global_fish_watch_daily_fleet_sum_2000'>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with arcpy.EnvManager(parallelProcessingFactor=\"99%\"):\n",
    "    arcpy.management.CalculateStatistics(in_raster_dataset = mosaic_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages'>Start Time: Wednesday, September 11, 2024 8:54:22 PM<br>Succeeded at Wednesday, September 11, 2024 8:54:23 PM (Elapsed Time: 1.70 seconds)<br></div><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'E:\\\\analysis\\\\GFW\\\\gfw_daily_fleet_2020.gdb\\\\global_fish_watch_daily_fleet_sum_2000'>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arcpy.management.SetMosaicDatasetProperties(\n",
    "    in_mosaic_dataset=mosaic_path,\n",
    "    rows_maximum_imagesize=15000,\n",
    "    columns_maximum_imagesize=15000,\n",
    "    allowed_compressions=\"None;JPEG;LZ77;LERC\",\n",
    "    default_compression_type=\"JPEG\",\n",
    "    JPEG_quality=85,\n",
    "    LERC_Tolerance=0.01,\n",
    "    resampling_type=\"NEAREST\",\n",
    "    clip_to_footprints=\"CLIP\",\n",
    "    footprints_may_contain_nodata=\"FOOTPRINTS_MAY_CONTAIN_NODATA\",\n",
    "    clip_to_boundary=\"CLIP\",\n",
    "    color_correction=\"NOT_APPLY\",\n",
    "    allowed_mensuration_capabilities=\"Basic\",\n",
    "    default_mensuration_capabilities=\"Basic\",\n",
    "    allowed_mosaic_methods=\"ByAttribute;NorthWest;Center;LockRaster;Nadir;Viewpoint;Seamline;None\",\n",
    "    default_mosaic_method=\"ByAttribute\",\n",
    "    order_field=\"StdTime\",\n",
    "    order_base=\"\",\n",
    "    sorting_order=\"DESCENDING\",\n",
    "    mosaic_operator=\"FIRST\",\n",
    "    blend_width=10,\n",
    "    view_point_x=600,\n",
    "    view_point_y=300,\n",
    "    max_num_per_mosaic=20,\n",
    "    cell_size_tolerance=0.8,\n",
    "    cell_size=\"0 0\",\n",
    "    metadata_level=\"Basic\",\n",
    "    transmission_fields=\"Name;MinPS;MaxPS;LowPS;HighPS;Tag;GroupName;ProductName;CenterX;CenterY;ZOrder;Shape_Length;Shape_Area;date;variable;StdTime;Dimensions;NONE\",\n",
    "    use_time=\"ENABLED\",\n",
    "    start_time_field=\"StdTime\",\n",
    "    end_time_field=\"StdTime\",\n",
    "    time_format=\"YYYY-MM-DD\",\n",
    "    geographic_transform=None,\n",
    "    max_num_of_download_items=20,\n",
    "    max_num_of_records_returned=1000,\n",
    "    data_source_type=\"SCIENTIFIC\",\n",
    "    minimum_pixel_contribution=1,\n",
    "    processing_templates=\"None;fishhours;hours\",\n",
    "    default_processing_template=\"None\",\n",
    "    time_interval=1,\n",
    "    time_interval_units=\"Days\",\n",
    "    product_definition=\"NONE\",\n",
    "    product_band_definitions=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "with arcpy.EnvManager(compression=\"'LERC' 0.010000\", parallelProcessingFactor=\"99%\", pyramid=\"PYRAMIDS -1 NEAREST JPEG 85 NO_SKIP NO_SIPS\"):\n",
    "    arcpy.management.CopyRaster(\n",
    "        in_raster=mosaic_path,\n",
    "        out_rasterdataset=os.path.join(analysis_directory, mosacic_name + \".crf\"),\n",
    "        config_keyword=\"\",\n",
    "        background_value=None,\n",
    "        nodata_value=\"\",\n",
    "        onebit_to_eightbit=\"NONE\",\n",
    "        colormap_to_RGB=\"NONE\",\n",
    "        pixel_type=\"\",\n",
    "        scale_pixel_value=\"NONE\",\n",
    "        RGB_to_Colormap=\"NONE\",\n",
    "        format=\"CRF\",\n",
    "        transform=\"NONE\",\n",
    "        process_as_multidimensional=\"ALL_SLICES\",\n",
    "        build_multidimensional_transpose=\"TRANSPOSE\"\n",
    "        # build_multidimensional_transpose=\"NO_TRANSPOSE\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Aggregate the daily multidimensional raster to monthly SUM for each variable (fishhours and hours)\n",
    "\n",
    "with arcpy.EnvManager(compression=\"'LERC' 0.010000\", parallelProcessingFactor=\"99%\", pyramid=\"PYRAMIDS -1 NEAREST JPEG 85 NO_SKIP NO_SIPS\", scratchWorkspace=analysis_directory):\n",
    "    out_multidimensional_raster = arcpy.ia.AggregateMultidimensionalRaster(\n",
    "        in_multidimensional_raster=os.path.join(analysis_directory, mosacic_name + \".crf\"),\n",
    "        dimension=\"StdTime\",\n",
    "        aggregation_method=\"SUM\",\n",
    "        variables=\"fishhours;hours\",\n",
    "        aggregation_def=\"INTERVAL_KEYWORD\",\n",
    "        interval_keyword=\"MONTHLY\",\n",
    "        interval_value=None,\n",
    "        interval_unit=\"\",\n",
    "        interval_ranges=None,\n",
    "        aggregation_function=\"\",\n",
    "        ignore_nodata=\"DATA\",\n",
    "        dimensionless=\"DIMENSIONS\",\n",
    "        percentile_value=90,\n",
    "        percentile_interpolation_type=\"NEAREST\"\n",
    "    )\n",
    "    out_multidimensional_raster.save(os.path.join(analysis_directory, mosacic_name.replace('daily', 'monthly') + \".crf\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
