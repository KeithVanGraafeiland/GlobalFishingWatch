{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## import libraries\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import arcpy\n",
    "from arcgis.features import GeoAccessor\n",
    "from arcgis import GIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CheckedOut'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## environment settings\n",
    "## more info: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
    "pd.options.mode.copy_on_write = True\n",
    "\n",
    "## To allow overwriting outputs change overwriteOutput option to True.\n",
    "arcpy.env.overwriteOutput = True\n",
    "arcpy.env.parallelProcessingFactor = \"90%\"\n",
    "\n",
    "## Check out any necessary licenses.\n",
    "arcpy.CheckOutExtension(\"spatial\")\n",
    "arcpy.CheckOutExtension(\"ImageAnalyst\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['c:\\\\Users\\\\keit8223\\\\AppData\\\\Local\\\\ESRI\\\\conda\\\\envs\\\\arcgispro-py3-clone\\\\Lib\\\\site-packages\\\\ipykernel_launcher.py', '--f=c:\\\\Users\\\\keit8223\\\\AppData\\\\Roaming\\\\jupyter\\\\runtime\\\\kernel-v31042749bb924fc2f7d1c1107c97c831948723940.json']\n",
      "2017\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print (sys.argv)\n",
    "\n",
    "val = input(\"Enter the year ypu want to process: \")\n",
    "print(val)\n",
    "# val = 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## define variables\n",
    "## connect to GIS\n",
    "gis = GIS()\n",
    "\n",
    "## directory where the daily fleet csv files from GFW are stored\n",
    "analysis_directory = os.path.join('E:\\\\analysis\\\\GFW', str(val), 'TIF')\n",
    "# print(analysis_directory)\n",
    "directory = r'F:\\Global Fishing Watch\\Fishing Intensity\\v2\\fleet-daily\\fleet-daily-csvs-100-v2-'+ str(val)\n",
    "# gear_list = ['fishing', 'drifting_longlines', 'seiners', 'purse_seines', 'tuna_purse_seines', 'other_purse_seines', 'other_seines', 'trollers', 'fixed_gear', 'pots_and_traps', 'set_longlines', 'set_gillnets', 'dredge_fishing', 'squid_jiggers', 'other']\n",
    "mosacic_name = 'global_fish_watch_daily_fleet_sum_' + str(val)\n",
    "processing_gdb = r'E:\\analysis\\GFW\\gfw_daily_fleet.gdb'\n",
    "mosaic_path = os.path.join(processing_gdb, mosacic_name)\n",
    "projectCoordinateSystem=\"GEOGCS[\\\"GCS_WGS_1984\\\",DATUM[\\\"D_WGS_1984\\\",SPHEROID[\\\"WGS_1984\\\",6378137.0,298.257223563]],PRIMEM[\\\"Greenwich\\\",0.0],UNIT[\\\"Degree\\\",0.0174532925199433]]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_directories():\n",
    "    if not os.path.exists(analysis_directory):\n",
    "        os.makedirs(analysis_directory)\n",
    "    if not arcpy.Exists(processing_gdb):\n",
    "        arcpy.management.CreateFileGDB(os.path.dirname(processing_gdb), os.path.basename(processing_gdb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess():\n",
    "            print(\"Starting processing of \" + filename + \"...\")\n",
    "            # Get the full path for the filename\n",
    "            file_path = os.path.join(directory, filename)\n",
    "            # Read the CSV file\n",
    "            # print(file_path)\n",
    "            global data\n",
    "            data = pd.read_csv(file_path)\n",
    "            # Get the first row as a table\n",
    "            first_row = data.head(1)\n",
    "            # Get the value in the first column\n",
    "            global value\n",
    "            value = first_row.iloc[0, 0]\n",
    "            # replace the '-' with '_'\n",
    "            value = value.replace('-', '_')\n",
    "            global tif_name1\n",
    "            tif_name1 = os.path.join(analysis_directory, \"daily_fleet_\" + value + \"_hours.tif\")\n",
    "            global fc_hours\n",
    "            fc_hours = os.path.join(processing_gdb, \"daily_fleet_\" + value + \"_hours\")\n",
    "            global tif_name2\n",
    "            tif_name2 = os.path.join(analysis_directory, \"daily_fleet_\" + value + \"_fishhours.tif\")\n",
    "            data['cell_ll_lat'] = data['cell_ll_lat'] + 0.005\n",
    "            data['cell_ll_lon'] = data['cell_ll_lon'] + 0.005\n",
    "            data.rename(columns={'cell_ll_lat': 'lat'}, inplace=True)\n",
    "            data.rename(columns={'cell_ll_lon': 'lon'}, inplace=True)\n",
    "            # print(\"Done with \" + value + \"...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_hours():\n",
    "    hours_select = data.loc[data['hours'] != 0]\n",
    "    hours_csv = os.path.join(analysis_directory, \"daily_fleet_\" + value + \"_hours.csv\")\n",
    "    hours_select.drop(columns=['date', 'flag', 'geartype', 'fishing_hours', 'mmsi_present'], inplace=True)\n",
    "    hours_select.to_csv(hours_csv, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_fishhours():\n",
    "    fishhours_select = data.loc[data['fishing_hours'] != 0]\n",
    "    fishhours_csv = os.path.join(analysis_directory, \"daily_fleet_\" + value + \"_fishhours.csv\")\n",
    "    fishhours_select.drop(columns=['date', 'flag', 'geartype', 'hours', 'mmsi_present'], inplace=True)\n",
    "    fishhours_select.to_csv(fishhours_csv, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_directories()\n",
    "\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith('.csv'):\n",
    "        preprocess()\n",
    "        process_hours()\n",
    "        process_fishhours()\n",
    "print(\"All done...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in os.listdir(analysis_directory):\n",
    "    if filename.endswith('fishhours.csv'):\n",
    "        csv_name = (os.path.basename(filename))\n",
    "        print(\"Processing \" + csv_name + \"...\")\n",
    "        fish_csv = (os.path.join(analysis_directory, os.path.splitext(filename)[0] + \".csv\"))\n",
    "        # print(fish_csv)\n",
    "        fish_tif = (os.path.join(analysis_directory, os.path.splitext(filename)[0] + \".tif\"))\n",
    "        # print(fish_tif)\n",
    "        fish_fc = (os.path.join(processing_gdb, os.path.splitext(os.path.basename(filename))[0]))\n",
    "        # print(fish_fc)\n",
    "        arcpy.management.XYTableToPoint(fish_csv, fish_fc, 'lon', 'lat', '', projectCoordinateSystem)\n",
    "        arcpy.conversion.PointToRaster(fish_fc, 'fishing_hours', fish_tif, \"SUM\", 'fishing_hours', 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in os.listdir(analysis_directory):\n",
    "    if filename.endswith('_hours.csv'):\n",
    "        csv_name = (os.path.basename(filename))\n",
    "        print(\"Processing \" + csv_name + \"...\")\n",
    "        hours_csv = (os.path.join(analysis_directory, os.path.splitext(filename)[0] + \".csv\"))\n",
    "        # print(hours_csv)\n",
    "        hours_tif = (os.path.join(analysis_directory, os.path.splitext(filename)[0] + \".tif\"))\n",
    "        # print(hours_tif)\n",
    "        hours_fc = (os.path.join(processing_gdb, os.path.splitext(os.path.basename(filename))[0]))\n",
    "        # print(hours_fc)\n",
    "        arcpy.management.XYTableToPoint(hours_csv, hours_fc, 'lon', 'lat', '', projectCoordinateSystem)\n",
    "        arcpy.conversion.PointToRaster(hours_fc, 'hours', hours_tif, \"SUM\", 'hours', 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages'>Start Time: Friday, September 27, 2024 1:05:59 PM<br>Succeeded at Friday, September 27, 2024 1:06:03 PM (Elapsed Time: 4.30 seconds)<br></div><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'E:\\\\analysis\\\\GFW\\\\gfw_daily_fleet.gdb\\\\global_fish_watch_daily_fleet_sum_2017'>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arcpy.management.CreateMosaicDataset(in_workspace = processing_gdb,\n",
    "                                     in_mosaicdataset_name = mosacic_name,\n",
    "                                     coordinate_system = projectCoordinateSystem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages'>Start Time: Friday, September 27, 2024 1:06:08 PM<br>2024-09-27T13:06:13.652: Loading raster datasets<br>2024-09-27T13:06:13.973: Completed crawling 730 data source items. Added 730 mosaic dataset items.<br>2024-09-27T13:06:13.975: Synchronizing crawled data source items<br>2024-09-27T13:06:13.981: Synchronizing items associated with raster type instance &#39;Raster Dataset&#39; [ID: 1].<br>2024-09-27T13:06:13.982: Distributing mosaic dataset operation across 32 parallel instances on the specified host: [KVANGRAAF].<br>2024-09-27T13:07:08.421: Completed synchronization: 730 items selected, 730 items synchronized.<br>2024-09-27T13:07:08.482: Computing cell size levels<br>2024-09-27T13:07:08.483: Computing unique cell size values<br>2024-09-27T13:07:16.162: Computing maximum cell size values<br>2024-09-27T13:07:16.164: Computing minimum cell size values<br>2024-09-27T13:07:16.165: Updating visibility values of selected items<br>2024-09-27T13:07:16.303: Computing maximum cell size for mosaic dataset<br>2024-09-27T13:07:16.309: Completed computing cell size ranges.<br>2024-09-27T13:07:23.681: Completed building boundary.<br>Succeeded at Friday, September 27, 2024 1:07:25 PM (Elapsed Time: 1 minutes 16 seconds)<br></div><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'E:\\\\analysis\\\\GFW\\\\gfw_daily_fleet.gdb\\\\global_fish_watch_daily_fleet_sum_2017'>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Add rasters to the mosaic dataset\n",
    "arcpy.management.AddRastersToMosaicDataset(in_mosaic_dataset = mosaic_path,\n",
    "                                           raster_type = \"Raster Dataset\",\n",
    "                                           filter = \"*.tif\",\n",
    "                                           input_path = analysis_directory,\n",
    "                                           sub_folder=\"SUBFOLDERS\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages'>Start Time: Friday, September 27, 2024 1:07:26 PM<br>Adding date to AMD_global_fish_watch_daily_fleet_sum_2017_CAT...<br>Succeeded at Friday, September 27, 2024 1:07:31 PM (Elapsed Time: 4.28 seconds)<br></div><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'E:\\\\analysis\\\\GFW\\\\gfw_daily_fleet.gdb\\\\global_fish_watch_daily_fleet_sum_2017'>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Calculate the date field\n",
    "arcpy.management.CalculateField(\n",
    "    in_table=mosaic_path,\n",
    "    field=\"date\",\n",
    "    expression=\"\"\"(!Name!.split('_')[3] + \"-\" + !Name!.split('_')[4] + \"-\" + !Name!.split('_')[2])\"\"\",\n",
    "    expression_type=\"PYTHON3\",\n",
    "    code_block=\"\",\n",
    "    field_type=\"DATE\",\n",
    "    enforce_domains=\"NO_ENFORCE_DOMAINS\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages'>Start Time: Friday, September 27, 2024 1:07:31 PM<br>Adding variable to AMD_global_fish_watch_daily_fleet_sum_2017_CAT...<br>Succeeded at Friday, September 27, 2024 1:07:36 PM (Elapsed Time: 4.26 seconds)<br></div><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'E:\\\\analysis\\\\GFW\\\\gfw_daily_fleet.gdb\\\\global_fish_watch_daily_fleet_sum_2017'>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Calculate the variable field\n",
    "arcpy.management.CalculateField(\n",
    "    in_table=mosaic_path,\n",
    "    field=\"variable\",\n",
    "    expression=\"\"\"(!Name!.split('_')[5].split('.')[0])\"\"\",\n",
    "    expression_type=\"PYTHON3\",\n",
    "    code_block=\"\",\n",
    "    field_type=\"TEXT\",\n",
    "    enforce_domains=\"NO_ENFORCE_DOMAINS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages'>Start Time: Friday, September 27, 2024 1:07:37 PM<br>Succeeded at Friday, September 27, 2024 1:07:40 PM (Elapsed Time: 2.91 seconds)<br></div><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'E:\\\\analysis\\\\GFW\\\\gfw_daily_fleet.gdb\\\\global_fish_watch_daily_fleet_sum_2017'>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Build multidimensional info\n",
    "arcpy.md.BuildMultidimensionalInfo(in_mosaic_dataset = mosaic_path,\n",
    "                                   variable_field = 'variable',\n",
    "                                   dimension_fields = 'date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculate statistics\n",
    "with arcpy.EnvManager(parallelProcessingFactor=\"99%\"):\n",
    "    arcpy.management.CalculateStatistics(in_raster_dataset = mosaic_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages'>Start Time: Friday, September 27, 2024 1:39:08 PM<br>Succeeded at Friday, September 27, 2024 1:39:10 PM (Elapsed Time: 1.92 seconds)<br></div><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'E:\\\\analysis\\\\GFW\\\\gfw_daily_fleet.gdb\\\\global_fish_watch_daily_fleet_sum_2017'>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Set mosaic dataset properties\n",
    "arcpy.management.SetMosaicDatasetProperties(\n",
    "    in_mosaic_dataset=mosaic_path,\n",
    "    rows_maximum_imagesize=15000,\n",
    "    columns_maximum_imagesize=15000,\n",
    "    allowed_compressions=\"LZ77;LERC\",\n",
    "    default_compression_type=\"LERC\",\n",
    "    JPEG_quality=85,\n",
    "    LERC_Tolerance=0,\n",
    "    resampling_type=\"NEAREST\",\n",
    "    clip_to_footprints=\"CLIP\",\n",
    "    footprints_may_contain_nodata=\"FOOTPRINTS_DO_NOT_CONTAIN_NODATA\",\n",
    "    clip_to_boundary=\"NOT_CLIP\",\n",
    "    color_correction=\"NOT_APPLY\",\n",
    "    allowed_mensuration_capabilities=\"Basic\",\n",
    "    default_mensuration_capabilities=\"Basic\",\n",
    "    allowed_mosaic_methods=\"ByAttribute;NorthWest;Center;LockRaster;Nadir;Viewpoint;Seamline;None\",\n",
    "    default_mosaic_method=\"ByAttribute\",\n",
    "    order_field=\"StdTime\",\n",
    "    order_base=\"YYYY/MM/DD\",\n",
    "    sorting_order=\"DESCENDING\",\n",
    "    mosaic_operator=\"FIRST\",\n",
    "    blend_width=10,\n",
    "    view_point_x=600,\n",
    "    view_point_y=300,\n",
    "    max_num_per_mosaic=500,\n",
    "    cell_size_tolerance=0.8,\n",
    "    cell_size=\"0 0\",\n",
    "    metadata_level=\"FULL\",\n",
    "    transmission_fields=\"Name;MinPS;MaxPS;LowPS;HighPS;Tag;GroupName;ProductName;CenterX;CenterY;ZOrder;Shape_Length;Shape_Area;date;variable;StdTime;Dimensions;NONE\",\n",
    "    use_time=\"ENABLED\",\n",
    "    start_time_field=\"StdTime\",\n",
    "    end_time_field=\"StdTime\",\n",
    "    time_format=\"YYYY-MM-DD\",\n",
    "    geographic_transform=None,\n",
    "    max_num_of_download_items=20,\n",
    "    max_num_of_records_returned=1000,\n",
    "    data_source_type=\"SCIENTIFIC\",\n",
    "    minimum_pixel_contribution=1,\n",
    "    processing_templates=\"None;fishhours;hours\",\n",
    "    default_processing_template=\"None\",\n",
    "    time_interval=1,\n",
    "    time_interval_units=\"Days\",\n",
    "    product_definition=\"NONE\",\n",
    "    product_band_definitions=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Copy raster to CRF\n",
    "with arcpy.EnvManager(compression=\"'LERC' 0.000000\", parallelProcessingFactor=\"99%\", pyramid=\"PYRAMIDS -1 NEAREST LZ77 85 NO_SKIP NO_SIPS\"):\n",
    "    arcpy.management.CopyRaster(\n",
    "        in_raster=mosaic_path,\n",
    "        out_rasterdataset=os.path.join(analysis_directory, mosacic_name + \".crf\"),\n",
    "        config_keyword=\"\",\n",
    "        background_value=None,\n",
    "        nodata_value=\"\",\n",
    "        onebit_to_eightbit=\"NONE\",\n",
    "        colormap_to_RGB=\"NONE\",\n",
    "        pixel_type=\"\",\n",
    "        scale_pixel_value=\"NONE\",\n",
    "        RGB_to_Colormap=\"NONE\",\n",
    "        format=\"CRF\",\n",
    "        transform=\"NONE\",\n",
    "        process_as_multidimensional=\"ALL_SLICES\",\n",
    "        build_multidimensional_transpose=\"TRANSPOSE\"\n",
    "        # build_multidimensional_transpose=\"NO_TRANSPOSE\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Aggregate the daily multidimensional raster to monthly SUM for each variable (fishhours and hours)\n",
    "with arcpy.EnvManager(compression=\"'LERC' 0.000000\", parallelProcessingFactor=\"99%\", pyramid=\"PYRAMIDS -1 NEAREST LZ77 85 NO_SKIP NO_SIPS\", scratchWorkspace=analysis_directory):\n",
    "    out_multidimensional_raster = arcpy.ia.AggregateMultidimensionalRaster(\n",
    "        in_multidimensional_raster=os.path.join(analysis_directory, mosacic_name + \".crf\"),\n",
    "        dimension=\"StdTime\",\n",
    "        aggregation_method=\"SUM\",\n",
    "        variables=\"fishhours;hours\",\n",
    "        aggregation_def=\"INTERVAL_KEYWORD\",\n",
    "        interval_keyword=\"MONTHLY\",\n",
    "        interval_value=None,\n",
    "        interval_unit=\"\",\n",
    "        interval_ranges=None,\n",
    "        aggregation_function=\"\",\n",
    "        ignore_nodata=\"DATA\",\n",
    "        dimensionless=\"DIMENSIONS\",\n",
    "        percentile_value=90,\n",
    "        percentile_interpolation_type=\"NEAREST\"\n",
    "    )\n",
    "    out_multidimensional_raster.save(os.path.join(analysis_directory, mosacic_name.replace('daily', 'monthly') + \".crf\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Aggregate the daily multidimensional raster to annual SUM for each variable (fishhours and hours)\n",
    "with arcpy.EnvManager(compression=\"'LERC' 0.000000\", parallelProcessingFactor=\"99%\", pyramid=\"PYRAMIDS -1 NEAREST LZ77 85 NO_SKIP NO_SIPS\", scratchWorkspace=analysis_directory):\n",
    "    out_multidimensional_raster = arcpy.ia.AggregateMultidimensionalRaster(\n",
    "        in_multidimensional_raster=os.path.join(analysis_directory, mosacic_name + \".crf\"),\n",
    "        dimension=\"StdTime\",\n",
    "        aggregation_method=\"SUM\",\n",
    "        variables=\"fishhours;hours\",\n",
    "        aggregation_def=\"ALL\",\n",
    "        interval_keyword=\"\",\n",
    "        interval_value=None,\n",
    "        interval_unit=\"\",\n",
    "        interval_ranges=None,\n",
    "        aggregation_function=\"\",\n",
    "        ignore_nodata=\"DATA\",\n",
    "        dimensionless=\"DIMENSIONS\",\n",
    "        percentile_value=90,\n",
    "        percentile_interpolation_type=\"NEAREST\"\n",
    "    )\n",
    "    out_multidimensional_raster.save(os.path.join(analysis_directory, mosacic_name.replace('daily', 'annual') + \".crf\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################\n",
    "## Try to publish the layers to AGOL ##\n",
    "##########################################################\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import arcgis\n",
    "# from arcgis.raster import *\n",
    "# from arcgis.raster.analytics import *\n",
    "# from arcgis.gis import GIS\n",
    "# # from AGOL_Credentials import AGOLusername, AGOLpassword\n",
    "\n",
    "# arcgis.env.verbose=True\n",
    "# # username = AGOLusername\n",
    "# # password = AGOLpassword\n",
    "# gis = GIS()\n",
    "\n",
    "# ## https://developers.arcgis.com/python/api-reference/arcgis.raster.analytics.html\n",
    "# import os\n",
    "\n",
    "# generate_raster_op = copy_raster(input_raster = os.path.join(analysis_directory, mosacic_name.replace('daily', 'annual') + \".crf\"),\n",
    "#                                      output_name = mosacic_name.replace('daily', 'annual'),\n",
    "#                                      process_as_multidimensional=True,\n",
    "#                                      raster_type_name=\"Raster Dataset\",\n",
    "#                                      tiles_only=True,\n",
    "#                                      gis=gis)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
